# 

## Paradigmen der Wissenschaft

Die Wissenschaft war:

* empirisch (vor 1000 Jahren)
* theoretisch (die letzten Jahrhunderte)
* computational (die letzten Jahrzehnte)
* explorativ (heute: eScience, Data Science)

Empirisch: Durch Wiederholung werden Konzepte verstanden

Theoretisch: Man packt Formeln in Modelle und kann neues Wissen ableiten..

Simulationen erweitern die Wissenschaft erheblich, Programmiersprache ALGOL 60. ALGOL 60 war ursprünglich zur einheitlichen Weitergabe von mathematischen Formeln.

CERN-Experiment: LHC - empirisch, Physiker bauen Theorien - machen Datenbankanfragen auf die gesamte Sammlung an Events

Buch: The Fourth Paradigm: Dara-Intensive Scientific Discovery, "Big Data"

in den großen Datenbeständen wird nach Korrelationen gesucht, man ignoriert die Kausalität teilweise

## Modell

Ein Modell: Abstraktion der Realität, auf die essentiellen Charakteristiken fokussiert und auf nicht relevante Eigenschaften verzichtet  
physikalische, mathematische, logische Darstellung eines Systems von Objekten, Phänomenen, oder Prozessen.

alle Nomen markieren und vereinfachen, Hierarchien finden, Modell entwickeln (Abstraktion der Welt)

Datenmodellierung und Prozessmodellierung

### Modellierungsarten in der Informatik
* **datenorientierte Modellierung:** Objekte, Klassen, relevante Eigenschaften (Attribute), Beziehungen zwischen Objekten
* **prozessorientierte Modellierung:** dynamische Abläufe im Fokus
* **objektorientierte Modellierung:** Zustand und Verhalten fällt zusammen in einer Klasse, fasst daten- und prozessorientierte Modellierung zusammen
* **semantische Modellierung:** Bedeutung soll in die Sache gebracht werden. Aus Wissen soll weiteres Wissen generiert werden.

## Datenorientierte Modellierung

Grundlegende Struktur der gespeicherten Daten: Datenmodell
* Daten
* Beziehungen zwischen Daten
* Bedeutung von Daten -> Menschen interpretieren die Semantik
* Integritätsbedingungen -> auch das ist Semantik, z.B. >=0, < 100
* Operatoren zur Manipulation der Daten

Namen sind sehr wichtig, auch im Projekt

### Datenmodelle
* Pretty Pictures (E/R Modell)  
* Relationen (Tabellen)

Das Relationelle Modell ist wichtiger für uns: Für Analysen und Anfragen  
Das E/R-Modell ist einfacher zu verstehen und zu kommunizieren

Tabellen sind fix im relationellen Modell, lässt sich gut abbilden

zwischen E/R-Modell und Tabellen zu übersetzen ist mechanistisch

die dritte Normalform soll erfüllt sein 

andere Modelle:  
* objektorientiertes Modell
* semistrukturiertes Modell

### Abstraktion als Element der Modellierung
1. Selektion der relevanten Daten
2. Strukturierung
3. Benennung der Daten

es gibt kein eindeutig richtiges Modell der Realität  
Zentrum aller Überlegungen ist das Prinzip der Abstraktion: der Prozess, auf die essentiellen Charakteristiken eines Objekten der Realität

## Drei-Ebenen-Architektur
ANSI-SPARC-Standard

* externe Ebene: Ebene, die dem Benutzer und den Anwendungsprogrammen angeboten wird
* kontextuelle Ebene: logische Ebene, zentrale Ebene, die nur dem Admin/Entwickler zur Verfügung steht
* interne Ebene: physische Speicherung auf der Platte (auch teilweise OS abhängig)

Trennung externe - kontextuelle Ebene: Sicherheit von manchen Daten und einfachere Erweiterung  
Die externe Ebene schränkt die Zugriffsmöglichkeiten sinnvoll ein.

## Instanzen, Schemas

Instanzen werden häufig gelesen/geschrieben/geändert  
logische Struktur der Information in einer Datenbank nennt man **Schema**

## Logische Datenunabhängigkeit

Ziel: Das konzeptionelle Schema kann geändert werden, ohne die externen Schemata ändern zu müssen  
dies wird erreicht durch die Trennung von externer und konzeptionelleer Schicht

## Physische Datenunabhängigkeit
Unterschied, wie die Daten abgespeichert werden und wie sie logisch dargestellt werden.

das physische Schema kann ausgetauscht werden (SQL), Dump aller SQL-Statements als Table-Operationen, in anderes Schema schieben und läuft wieder

## Datenbankentwurfsprojekt
1. konzeptioneller Entwurf: Interviews auf verschiedenen Ebenen in einem Unternehmen -> ein E/R-Diagramm
2. logischer Entwurf: auf Knopfdruck aus dem E/R-Diagramm, funktionale Abhängigkeit (Normalisierung)
3. physischer Entwurf: physisches Schema auf dem logischen Entwurf 

## Komponenten eines DBMS

### Schnittstellen für Abfragen
Nutzer stellen Anfragen an die Datenbanken

**4 Benutzertypen:**
* naiver Benutzer (standardisierte Schnittstelle, z.B. Formular)
* Spezialist: Query Language Benutzer (z.B. SQL)
* Anwendungsprogrammierer: schreibt die Programme, Formulare für naive Nutzer, LAMP (Linux+Apache+MySQL+PHP), JDBC, Programmiersprache
* Datenbankadministrator: Zugriff über alle Ebenen. Was darf in der externen Ebene gesehen werden, wie wird die interne Ebene strukturiert, damit die Zugriffe effizient sind.

jeder Benutzertyp hat eine eigenes Interface

### Abfrageprozessor
Wie kann ich die Abfragen der Nutzer abarbeiten?  
bekommt den Input der unterschiedlichen Benutzer, meist in SQL
die Anfrage wird in einen relationellen Ausdruck umgewandelt

auch Datenmanipulation  
DDL Interpreter, neue Tabellen erzeugen, ändern, Tabellen löschen  
Abfrageabarbeitung (Query Evaluation Engine): Basisoperationen  

#### Datenmanipulationssprachen
Zwei Klassen: prozedural und deklarativ (nicht-prozedural)

SQL ist der wichtigste Vertreter für nicht-prozedurale DMLs

```sql
select student.student_name
from student
where student.strkz = 926
```

manchmal ist SQL eingebettet in Programmiersprachen (embedded SQL)

gleich mächtig wie relationale Algebra

### Speicher Manager
Schnittstelle zwischen Daten und dem Abfrageprozessor
wie bei Betriebssystemen atomare Operationen, Paging, Caching, ...

### Plattenspeicher
physische Speicherung auf den Platten

### Transaktionsmanager
garantiert, dass die Datenbank in einem konsistenten Zustand bleibt, trotz Systemabstürzen

### ACID Eigenschaften
* **Atomicity:** Atomarität, Operation ganz oder gar nicht durchführen
* **Consistency:** Zustände zwischen Transaktionen sind konsistent und man sieht nie Zwischenzustände
* **Isolation:** Transaktionen sind voneinander unabhängig, kein Thrashing oder Deadlock
* **Durability:** nach commits kann nicht mehr zurück auf einen vorigen Zustand gegangen werden

### Plattenspeicher
Reihe von Datenstrukturen, die die physische Implementierung der Datenbank repräsentieren
Daten, Indizes, Data Dictionary, ...

### Datentransfer
Hauptspeicher - Platte  
Mechanismus eines OS
Blöcke mit 4K

Puffer, mit dirty blocks, die zurückgeschrieben werden: Buffer manager  
so viel wie möglich, aber auch nur so viel wie nötig im Hauptspeicher halten

# Applikationsarchitekturen
zwei-Schichten: für Administratoren sicher, für Nutzer nicht  
drei-Schichten: Webapplikation oder Middleware (Projekt)

SOA (Service Orientierten Architektur)
service requester, Verzeichnis/broker, service provider macht map reduce

